{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of contours = 160\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mat is not a numpy array, neither a scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-eaeba582ab86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'contours'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: mat is not a numpy array, neither a scalar"
     ]
    }
   ],
   "source": [
    "image=cv2.imread('C://Users//jihad//Downloads//cat2.jpg')\n",
    "cv2.imshow('original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "img_gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edged= cv2.Canny(img_gray,30,200)\n",
    "cv2.imshow('canny', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "_,contours,_= cv2.findContours(edged, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('canny edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print('number of contours = '+ str(len(contours)))\n",
    "\n",
    "cv2.drawContours(image, contours,-1, (0,255,0),3)\n",
    "cv2.imshow('contours', contours)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of contours =  7\n"
     ]
    }
   ],
   "source": [
    "image=cv2.imread('C://Users//jihad//Downloads//shapes2.jpg')\n",
    "cv2.imshow('original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "blank_image= np.zeros((image.shape[0], image.shape[1],3))\n",
    "\n",
    "original_image= image\n",
    "\n",
    "gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edged= cv2.Canny(gray,50,200)\n",
    "cv2.imshow('canny', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "_, contours, _= cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "print('number of contours = ', len(contours))\n",
    "\n",
    "cv2.drawContours(blank_image, contours,-1, (0,255,0),3)\n",
    "cv2.imshow('all contours', blank_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.drawContours(image, contours,-1, (0,255,0),3)\n",
    "cv2.imshow('all contours', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load image and keep a copy\n",
    "image = cv2.imread(\"C://Users//jihad//Downloads//MasteringComputerVision-V1.03//Master OpenCV//images//house.jpg\")\n",
    "orig_image = image.copy()\n",
    "cv2.imshow('Original Image', orig_image)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Grayscale and binarize\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours \n",
    "_,contours,_ = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Iterate through each contour and compute the bounding rectangle\n",
    "for c in contours:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(orig_image,(x,y),(x+w,y+h),(0,0,255),2)    \n",
    "    cv2.imshow('Bounding Rectangle', orig_image)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "    \n",
    "# Iterate through each contour and compute the approx contour\n",
    "for c in contours:\n",
    "    # Calculate accuracy as a percent of the contour perimeter\n",
    "    accuracy = 0.03 * cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, accuracy, True)\n",
    "    cv2.drawContours(image, [approx], 0, (0, 255, 0), 2)\n",
    "    cv2.imshow('Approx Poly DP', image)\n",
    "    \n",
    "cv2.waitKey(0)   \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('C://Users//jihad//Downloads//MasteringComputerVision-V1.03//Master OpenCV//images//hand.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Threshold the image\n",
    "ret, thresh = cv2.threshold(gray, 176, 255, 0)\n",
    "\n",
    "# Find contours \n",
    "_,contours,_ = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "# Sort Contors by area and then remove the largest frame contour\n",
    "n = len(contours) -1\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=False)[:n]\n",
    "\n",
    "# Iterate through contours and draw the convex hull\n",
    "for c in contours:\n",
    "    hull = cv2.convexHull(c)\n",
    "    cv2.drawContours(image, [hull], 0, (0, 255, 0), 2)\n",
    "    cv2.imshow('Convex Hull', image)\n",
    "\n",
    "cv2.waitKey(0)    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13081816783853514\n",
      "0.1590200533978871\n",
      "0.1498791568252558\n",
      "0.07094034474475601\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the shape template or reference image\n",
    "template = cv2.imread('C://Users//jihad//Downloads//MasteringComputerVision-V1.03//Master OpenCV//images//4star.jpg',0)\n",
    "cv2.imshow('Template', template)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Load the target image with the shapes we're trying to match\n",
    "target = cv2.imread('C://Users//jihad//Downloads//MasteringComputerVision-V1.03//Master OpenCV//images//shapestomatch.jpg')\n",
    "target_gray = cv2.cvtColor(target,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold both images first before using cv2.findContours\n",
    "ret, thresh1 = cv2.threshold(template, 127, 255, 0)\n",
    "ret, thresh2 = cv2.threshold(target_gray, 127, 255, 0)\n",
    "\n",
    "# Find contours in template\n",
    "_,contours,_ = cv2.findContours(thresh1, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# We need to sort the contours by area so that we can remove the largest\n",
    "# contour which is the image outline\n",
    "sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "# We extract the second largest contour which will be our template contour\n",
    "template_contour = contours[1]\n",
    "\n",
    "# Extract contours from second target image\n",
    "_,contours,_ = cv2.findContours(thresh2, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for c in contours:\n",
    "    # Iterate through each contour in the target image and \n",
    "    # use cv2.matchShapes to compare contour shapes\n",
    "    match = cv2.matchShapes(template_contour, c, 3, 0.0)\n",
    "    print (match)\n",
    "    # If the match value is less than 0.15 we\n",
    "    if match < 0.15:\n",
    "        closest_contour = c\n",
    "    else:\n",
    "        closest_contour = [] \n",
    "                \n",
    "cv2.drawContours(target, [closest_contour], -1, (0,255,0), 3)\n",
    "cv2.imshow('Output', target)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
